# CrewAI Multi-Agent SA Call Analyzer Configuration
# This app uses 4 specialized AI agents to analyze Solution Architect performance

# ===== OPTION 1: Use Anthropic API (Recommended) =====
# Sign up at https://console.anthropic.com/
ANTHROPIC_API_KEY=your_api_key_here

# Model Selection (affects cost and quality)
# - claude-3-5-haiku-20241022   (~$0.25-0.50 per call) - Fast, cost-effective, great quality
# - claude-3-5-sonnet-20241022  (~$1.50-2.50 per call) - Best quality, deeper insights
MODEL_NAME=claude-3-5-haiku-20241022

# ===== OPTION 2: Use LiteLLM Proxy (Local/Self-hosted) =====
# Set USE_LITELLM=true to use your local LiteLLM instance instead of Anthropic
USE_LITELLM=false

# LiteLLM configuration (only needed if USE_LITELLM=true)
LITELLM_BASE_URL=http://localhost:4000
LITELLM_API_KEY=dummy

# When using LiteLLM, set MODEL_NAME to whatever model you configured:
# Examples:
# - gpt-4o-mini               (via OpenAI, cheap and good)
# - gpt-3.5-turbo             (via OpenAI, very cheap)
# - ollama/llama3.1:70b       (free, runs locally via Ollama)
# - groq/llama-3.1-70b        (fast and free via Groq)
# - any model your LiteLLM proxy supports

# ===== Gong API Integration (Optional) =====
# Allows fetching transcripts directly from Gong by URL
# Get credentials from: Settings > API in Gong (requires Technical Admin)
GONG_ACCESS_KEY=your_gong_access_key_here
GONG_SECRET_KEY=your_gong_secret_key_here

# ===== Observability (Optional) =====
# OpenInference tracing with Arize AX
# Sign up at https://arize.com/ to get your credentials
ARIZE_API_KEY=your_arize_api_key_here
ARIZE_SPACE_ID=your_space_id_here

# Disable CrewAI's built-in tracing (we use Arize instead)
OTEL_SDK_DISABLED=false
CREWAI_TELEMETRY_OPT_OUT=true
